#============================  Config Reloading ===============================

# Config reloading allows to dynamically load modules. Each file which is
# monitored must contain one or multiple modules as a list.
metricbeat.config.modules:
  path: ${path.config}/modules.d/*.yml
  reload.period: 10s
  reload.enabled: true

#==========================  Modules configuration =============================
metricbeat.modules:
  #-------------------------------- System Module --------------------------------
  - module: system
    metricsets:
      - cpu # CPU usage
      - load # CPU load averages
      - memory # Memory usage
      - network # Network IO
      - process # Per process metrics
      - process_summary # Process summary
      - uptime # System Uptime
      - socket_summary # Socket summary
      #- core           # Per CPU core usage
      #- diskio         # Disk IO
      #- filesystem     # File system usage for each mountpoint
      #- fsstat         # File system summary metrics
      #- raid           # Raid
      #- socket         # Sockets and connection info (linux only)
      #- service        # systemd service information
    enabled: true
    period: 10s
    processes: ['.*']

    # Configure the mount point of the hostâ€™s filesystem for use in monitoring a host from within a container
    #system.hostfs: "/hostfs"

    # Configure the metric types that are included by these metricsets.
    cpu.metrics: ['percentages', 'normalized_percentages'] # The other available option is ticks.
    core.metrics: ['percentages'] # The other available option is ticks.

    # A list of filesystem types to ignore. The filesystem metricset will not
    # collect data from filesystems matching any of the specified types, and
    # fsstats will not include data from these filesystems in its summary stats.
    # If not set, types associated to virtual filesystems are automatically
    # added when this information is available in the system (e.g. the list of
    # `nodev` types in `/proc/filesystem`).
    #filesystem.ignore_types: []

    # These options allow you to filter out all processes that are not
    # in the top N by CPU or memory, in order to reduce the number of documents created.
    # If both the `by_cpu` and `by_memory` options are used, the union of the two sets
    # is included.
    #process.include_top_n:

    # Set to false to disable this feature and include all processes
    #enabled: true

    # How many processes to include from the top by CPU. The processes are sorted
    # by the `system.process.cpu.total.pct` field.
    #by_cpu: 0

    # How many processes to include from the top by memory. The processes are sorted
    # by the `system.process.memory.rss.bytes` field.
    #by_memory: 0

    # If false, cmdline of a process is not cached.
    #process.cmdline.cache.enabled: true

    # Enable collection of cgroup metrics from processes on Linux.
    #process.cgroups.enabled: true

    # A list of regular expressions used to whitelist environment variables
    # reported with the process metricset's events. Defaults to empty.
    #process.env.whitelist: []

    # Include the cumulative CPU tick values with the process metrics. Defaults
    # to false.
    #process.include_cpu_ticks: false

    # Raid mount point to monitor
    #raid.mount_point: '/'

    # Configure reverse DNS lookup on remote IP addresses in the socket metricset.
    #socket.reverse_lookup.enabled: false
    #socket.reverse_lookup.success_ttl: 60s
    #socket.reverse_lookup.failure_ttl: 60s

    # Diskio configurations
    #diskio.include_devices: []

    # Filter systemd services by status or sub-status
    #service.state_filter: ["active"]

    # Filter systemd services based on a name pattern
    #service.pattern_filter: ["ssh*", "nfs*"]

# ================================= Processors =================================

# Processors are used to reduce the number of fields in the exported event or to
# enhance the event with external metadata. This section defines a list of
# processors that are applied one by one and the first one receives the initial
# event:
#
#   event -> filter1 -> event1 -> filter2 ->event2 ...
#
# The supported processors are drop_fields, drop_event, include_fields,
# decode_json_fields, and add_cloud_metadata
processors:
  - add_host_metadata: ~

# ============================= X-Pack Monitoring ==============================
# Metricbeat can export internal metrics to a central Elasticsearch monitoring
# cluster.  This requires xpack monitoring to be enabled in Elasticsearch.  The
# reporting is disabled by default.

# Set to true to enable the monitoring reporter.
monitoring.enabled: true

# ================================== Template ==================================

# A template is used to set the mapping in Elasticsearch
# By default template loading is enabled and the template is loaded.
# These settings can be adjusted to load your own template or overwrite existing ones.

# Set to false to disable template loading.
#setup.template.enabled: true

# Select the kind of index template. From Elasticsearch 7.8, it is possible to
# use component templates. Available options: legacy, component, index.
# By default metricbeat uses the legacy index templates.
setup.template.type: index

# Template name. By default the template name is "metricbeat-%{[agent.version]}"
# The template name and pattern has to be set in case the Elasticsearch index pattern is modified.
#setup.template.name: "metricbeat-%{[agent.version]}"

# Template pattern. By default the template pattern is "-%{[agent.version]}-*" to apply to the default index settings.
# The first part is the version of the beat and then -* is used to match all daily indices.
# The template name and pattern has to be set in case the Elasticsearch index pattern is modified.
#setup.template.pattern: "metricbeat-%{[agent.version]}-*"

# Path to fields.yml file to generate the template
#setup.template.fields: "${path.config}/fields.yml"

# A list of fields to be added to the template and Kibana index pattern. Also
# specify setup.template.overwrite: true to overwrite the existing template.
#setup.template.append_fields:
#- name: field_name
#  type: field_type

# Enable JSON template loading. If this is enabled, the fields.yml is ignored.
#setup.template.json.enabled: false

# Path to the JSON template file
#setup.template.json.path: "${path.config}/template.json"

# Name under which the template is stored in Elasticsearch
#setup.template.json.name: ""

# Overwrite existing template
# Do not enable this option for more than one instance of metricbeat as it might
# overload your Elasticsearch with too many update requests.
#setup.template.overwrite: false

# Elasticsearch template settings
setup.template.settings:

  # A dictionary of settings to place into the settings.index dictionary
  # of the Elasticsearch template. For more details, please check
  # https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html
  #index:
  #number_of_shards: 1
  #codec: best_compression

  # A dictionary of settings for the _source field. For more details, please check
  # https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-source-field.html
  #_source:
  #enabled: false

# ====================== Index Lifecycle Management (ILM) ======================

# Configure index lifecycle management (ILM). These settings create a write
# alias and add additional settings to the index template. When ILM is enabled,
# output.elasticsearch.index is ignored, and the write alias is used to set the
# index name.

# Enable ILM support. Valid values are true, false, and auto. When set to auto
# (the default), the Beat uses index lifecycle management when it connects to a
# cluster that supports ILM; otherwise, it creates daily indices.
# setup.ilm.enabled: auto

# Set the prefix used in the index lifecycle write alias name. The default alias
# name is 'metricbeat-%{[agent.version]}'.
# setup.ilm.rollover_alias: 'metricbeat'

# Set the rollover index pattern. The default is "%{now/d}-000001".
#setup.ilm.pattern: "{now/d}-000001"

# Set the lifecycle policy name. The default policy name is
# 'beatname'.
#setup.ilm.policy_name: "mypolicy"

# The path to a JSON file that contains a lifecycle policy configuration. Used
# to load your own lifecycle policy.
setup.ilm.policy_file: ${path.config}/ilm-config.json

# Disable the check for an existing lifecycle policy. The default is true. If
# you disable this check, set setup.ilm.overwrite: true so the lifecycle policy
# can be installed.
#setup.ilm.check_exists: true

# Overwrite the lifecycle policy at startup. The default is false.
#setup.ilm.overwrite: false

# ---------------------------- Elasticsearch Output ----------------------------
output.elasticsearch:
  # Array of hosts to connect to.
  # Scheme and port can be left out and will be set to the default (http and 9200)
  # In case you specify and additional path, the scheme is required: http://localhost:9200/path
  # IPv6 addresses should always be defined as: https://[2001:db8::1]:9200
  hosts: ['${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}']

  # Authentication credentials - either API key or username/password.
  #api_key: "id:api_key"
  username: '${ELASTIC_USERNAME}'
  password: '${ELASTIC_PASSWORD}'

# ================================= Dashboards =================================

# These settings control loading the sample dashboards to the Kibana index. Loading
# the dashboards are disabled by default and can be enabled either by setting the
# options here, or by using the `-setup` CLI flag or the `setup` command.
# setup:
#   kibana.host: '${KIBANA_HOST}:${KIBANA_PORT}'
#   dashboards.enabled: true

# ================================== Logging ===================================

# There are four options for the log output: file, stderr, syslog, eventlog
# The file output is the default.

# Logging to rotating files. Set logging.to_files to false to disable logging to
# files.
logging.to_files: false
